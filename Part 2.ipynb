{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cell below imports the relevant libraries and read the data from the specified files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('creditdefault_train.csv', header='infer')\n",
    "test_data = pd.read_csv('creditdefault_test.csv', header='infer')\n",
    "\n",
    "\n",
    "\n",
    "# X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "# X2: Gender (1 = male; 2 = female).\n",
    "# X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "# X4: Marital status (1 = married; 2 = single; 3 = others).\n",
    "# X5: Age (year).\n",
    "# X6 - X11: History of past payment. One tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "# X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "# X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
    "\n",
    "\n",
    "\n",
    "# Separate classes from dataset\n",
    "y_train = train_data['Y']\n",
    "X_train = train_data.drop(['Y'],axis=1)\n",
    "\n",
    "y_test = test_data['Y']\n",
    "X_test = test_data.drop(['Y'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.6913333333333334, 2: 0.7639333333333334, 3: 0.734, 4: 0.7664, 5: 0.7518}\n"
     ]
    }
   ],
   "source": [
    "# KNN for 1 to 10\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = {}\n",
    "total_k = 6\n",
    "\n",
    "for k in range(1, total_k):\n",
    "    \n",
    "    # Initialize KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict classes for testing data\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Store the total accuracy values and percentage\n",
    "    scores[k] = metrics.accuracy_score(y_test, y_pred, normalize = False) / len(y_test)\n",
    "    \n",
    "\n",
    "print(scores)  \n",
    "\n",
    "\n",
    "# Juan: I need to build a function to find the best of scores\n",
    "# Use this: print('Accuracy on test data is %.2f' % (accuracy_score(testY, predY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8001333333333334\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=12)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred, normalize = False) / len(y_test)\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing Python and any relevant libraries,\\nyou are required to build the best predictive model\\nby tuning models using cross validation on the training dataset\\nwith each of the following algorithms (seen in class):\\nkNN, decision trees, Random Forest, Bagging, Boosting, and SVM.\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Using Python and any relevant libraries,\n",
    "you are required to build the best predictive model\n",
    "by tuning models using cross validation on the training dataset\n",
    "with each of the following algorithms (seen in class):\n",
    "kNN, decision trees, Random Forest, Bagging, Boosting, and SVM.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9997333333333334, 0.8704, 0.9997333333333334]\n",
      "[0.8154, 0.8186666666666667, 0.7974666666666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Random Forest'), Text(0, 0, 'Bagging'), Text(0, 0, 'AdaBoost')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAFlCAYAAADh444SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAdzElEQVR4nO3df7DdeV3f8efLxAgtCxT32tL8IBnMgpHqItdIxVEQmGZhTKxdNBlp2c6WDFMjKkgbRpvuxBlL2bbMMEZLUFxgCmGhFiPERsVFRXeZXGR3IVmit9mVXNOZDbAgVGAJvPvH+QaOd8/NPZuce8/J+TwfM2fy/X6+n/M975zvuZ/7ut/v93y/qSokSZKk1nzTuAuQJEmSxsEgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJatLacb3wtddeW5s3bx7Xy0vSZfvIRz7yqaqaGXcdq8kxW9LVbKlxe2xBePPmzczNzY3r5SXpsiX5q3HXsNocsyVdzZYatz01QpIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUnLBuEkb0nyYJKPL7E8Sd6YZD7JvUm+Z/RlSpIkSaM1zB7h24Adl1h+A7C1e+wFfu3Ky5IkSZJW1rJBuKr+GPjMJbrsAt5WPXcBT0zy5FEVKEmSJK2EtSNYx3rgbN/8Qtf2fxd3TLKX3l5jNm3adFkvtnn/+y/reYIHXvficZegFeLPxeXz50KtcJy4fI4T02sUQTgD2mpQx6o6DBwGmJ2dHdhHkjQ9DF+Xz/AlrbxRXDViAdjYN78BODeC9UqSJEkrZhRB+Cjwr7qrRzwb+FxVPeK0CEmSJGmSDHP5tHcCdwJPS7KQ5OYkr0jyiq7LMeAMMA+8Gfi3K1atJGlZSXYkOd1d1nL/gOWbktyR5KPdZS9fNI46JWnclj1HuKr2LLO8gJ8aWUWSpMuWZA1wCHghvVPXTiQ5WlWn+rr9InB7Vf1akm30dmhsXvViJWnMvLOcJE2X7cB8VZ2pqoeBI/Quc9mvgMd300/A73VIapRBWJKmy1KXtOx3C/DSJAv09gb/9KAVJdmbZC7J3Pnz51eiVkkaq1FcPk2SNDmGuaTlHuC2qvqvSf4p8PYkz6iqr/2dJ3nJS2lFeFnByzfqywq6R1iSpsswl7S8GbgdoKruBB4DXLsq1UnSBDEIS9J0OQFsTbIlyTpgN73LXPb7JPB8gCTfQS8Ie+6DpOYYhCVpilTVBWAfcBy4j97VIU4mOZhkZ9ft1cDLk9wDvBO4qbsCkCQ1xXOEJWnKVNUxel+C62870Dd9CnjOatclSZPGPcKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUlrx12Arl6b979/3CVctR543YvHXYIkSc1zj7AkSZKaZBCWpCmTZEeS00nmk+wfsPwNSe7uHn+R5LPjqFOSxs1TIyRpiiRZAxwCXggsACeSHK2qUxf7VNXP9fX/aeCZq16oJE0A9whL0nTZDsxX1Zmqehg4Auy6RP89wDtXpTJJmjAGYUmaLuuBs33zC13bIyR5CrAF+MMllu9NMpdk7vz58yMvVJLGzSAsSdMlA9pqib67gfdU1VcHLayqw1U1W1WzMzMzIytQkiaFQViSpssCsLFvfgNwbom+u/G0CEkNMwhL0nQ5AWxNsiXJOnph9+jiTkmeBvwD4M5Vrk+SJoZBWJKmSFVdAPYBx4H7gNur6mSSg0l29nXdAxypqqVOm5Ckqefl0yRpylTVMeDYorYDi+ZvWc2aJGkSuUdYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWrSUEE4yY4kp5PMJ9k/YPmmJHck+WiSe5O8aPSlSpIkSaOzbBBOsgY4BNwAbAP2JNm2qNsv0ruN5zPp3df+V0ddqCRJkjRKw+wR3g7MV9WZqnoYOALsWtSngMd3008Azo2uREmSJGn0hgnC64GzffMLXVu/W4CXJlmgd3/7nx60oiR7k8wlmTt//vxllCtJkiSNxjBBOAPaatH8HuC2qtoAvAh4e5JHrLuqDlfVbFXNzszMPPpqJUmSpBEZJggvABv75jfwyFMfbgZuB6iqO4HHANeOokBJkiRpJQwThE8AW5NsSbKO3pfhji7q80ng+QBJvoNeEPbcB0mSJE2sZYNwVV0A9gHHgfvoXR3iZJKDSXZ23V4NvDzJPcA7gZuqavHpE5IkSdLEWDtMp6o6Ru9LcP1tB/qmTwHPGW1pkiRJ0srxznKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLElTJsmOJKeTzCfZv0SfH09yKsnJJO9Y7RolaRKsHXcBkqTRSbIGOAS8EFgATiQ5WlWn+vpsBV4LPKeqHkrybeOpVpLGyz3CkjRdtgPzVXWmqh4GjgC7FvV5OXCoqh4CqKoHV7lGSZoIBmFJmi7rgbN98wtdW7/rgOuS/GmSu5LsGLSiJHuTzCWZO3/+/AqVK0njYxCWpOmSAW21aH4tsBV4LrAH+PUkT3zEk6oOV9VsVc3OzMyMvFBJGjeDsCRNlwVgY9/8BuDcgD6/XVVfqar7gdP0grEkNcUgLEnT5QSwNcmWJOuA3cDRRX3eCzwPIMm19E6VOLOqVUrSBDAIS9IUqaoLwD7gOHAfcHtVnUxyMMnOrttx4NNJTgF3AK+pqk+Pp2JJGh8vnyZJU6aqjgHHFrUd6Jsu4FXdQ5Ka5R5hSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkjRlkuxIcjrJfJL9A5bflOR8kru7x78ZR52SNG5rx12AJGl0kqwBDgEvBBaAE0mOVtWpRV3fVVX7Vr1ASZog7hGWpOmyHZivqjNV9TBwBNg15pokaSINFYSXO8zW9fnxJKeSnEzyjtGWKUka0nrgbN/8Qte22L9Icm+S9yTZOGhFSfYmmUsyd/78+ZWoVZLGatkg3HeY7QZgG7AnybZFfbYCrwWeU1XfCfzsCtQqSVpeBrTVovnfATZX1XcBfwC8ddCKqupwVc1W1ezMzMyIy5Sk8Rtmj/Awh9leDhyqqocAqurB0ZYpSRrSAtC/h3cDcK6/Q1V9uqq+3M2+GXjWKtUmSRNlmCA8zGG264DrkvxpkruS7Bi0Ig+zSdKKOwFsTbIlyTpgN3C0v0OSJ/fN7gTuW8X6JGliDHPViGEOs60FtgLPpbf34U+SPKOqPvt3nlR1GDgMMDs7u3gdkqQrVFUXkuwDjgNrgLdU1ckkB4G5qjoKvDLJTuAC8BngprEVLEljNEwQXvYwW9fnrqr6CnB/ktP0gvGJkVQpSRpaVR0Dji1qO9A3/Vp63+uQpKYNc2rEsofZgPcCzwNIci29UyXOjLJQSZIkaZSWDcJVdQG4eJjtPuD2i4fZukNrdMs+neQUcAfwmqr69EoVLUmSJF2poe4sN8RhtgJe1T0kSZKkieed5SRJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWpCmTZEeS00nmk+y/RL8bk1SS2dWsT5ImhUFYkqZIkjXAIeAGYBuwJ8m2Af2uAV4JfHh1K5SkyWEQlqTpsh2Yr6ozVfUwcATYNaDfLwGvB760msVJ0iQxCEvSdFkPnO2bX+javi7JM4GNVfW+S60oyd4kc0nmzp8/P/pKJWnMDMKSNF0yoK2+vjD5JuANwKuXW1FVHa6q2aqanZmZGWGJkjQZDMKSNF0WgI198xuAc33z1wDPAD6Y5AHg2cBRvzAnqUUGYUmaLieArUm2JFkH7AaOXlxYVZ+rqmuranNVbQbuAnZW1dx4ypWk8TEIS9IUqaoLwD7gOHAfcHtVnUxyMMnO8VYnSZNl7bgLkCSNVlUdA44tajuwRN/nrkZNkjSJ3CMsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCYZhCVJktSkoYJwkh1JTieZT7L/Ev1uTFJJZkdXoiRJkjR6ywbhJGuAQ8ANwDZgT5JtA/pdA7wS+PCoi5QkSZJGbZg9wtuB+ao6U1UPA0eAXQP6/RLweuBLI6xPkiRJWhHDBOH1wNm++YWu7euSPBPYWFXvG2FtkiRJ0ooZJghnQFt9fWHyTcAbgFcvu6Jkb5K5JHPnz58fvkpJkiRpxIYJwgvAxr75DcC5vvlrgGcAH0zyAPBs4OigL8xV1eGqmq2q2ZmZmcuvWpIkSbpCwwThE8DWJFuSrAN2A0cvLqyqz1XVtVW1uao2A3cBO6tqbkUqliRJkkZg2SBcVReAfcBx4D7g9qo6meRgkp0rXaAkSZK0EtYO06mqjgHHFrUdWKLvc6+8LEmSJGlleWc5SZIkNckgLEmSpCYZhCVpyiTZkeR0kvkk+wcsf0WSjyW5O8mHBt0tVJJaYBCWpCmSZA1wCLgB2AbsGRB031FV/6Sqrqd3R9D/tsplStJEMAhL0nTZDsxX1Zmqehg4Auzq71BVf9M3+/fpu0mSJLVkqKtGSJKuGuuBs33zC8D3Le6U5KeAVwHrgB8etKIke4G9AJs2bRp5oZI0bu4RlqTpkgFtj9jjW1WHquqpwL8HfnHQirwbqKRpZxCWpOmyAGzsm98AnLtE/yPAj65oRZI0oQzCkjRdTgBbk2xJsg7YDRzt75Bka9/si4G/XMX6JGlieI6wJE2RqrqQZB9wHFgDvKWqTiY5CMxV1VFgX5IXAF8BHgJeNr6KJWl8DMKSNGWq6hhwbFHbgb7pn1n1oiRpAnlqhCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS9KUSbIjyekk80n2D1j+qiSnktyb5ANJnjKOOiVp3AzCkjRFkqwBDgE3ANuAPUm2Ler2UWC2qr4LeA/w+tWtUpImg0FYkqbLdmC+qs5U1cPAEWBXf4equqOq/rabvQvYsMo1StJEMAhL0nRZD5ztm1/o2pZyM/C7K1qRJE2oteMuQJI0UhnQVgM7Ji8FZoEfWmL5XmAvwKZNm0ZVnyRNDPcIS9J0WQA29s1vAM4t7pTkBcAvADur6suDVlRVh6tqtqpmZ2ZmVqRYSRong7AkTZcTwNYkW5KsA3YDR/s7JHkm8CZ6IfjBMdQoSRPBICxJU6SqLgD7gOPAfcDtVXUyycEkO7tutwKPA96d5O4kR5dYnSRNNc8RlqQpU1XHgGOL2g70Tb9g1YuSpAnkHmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKThgrCSXYkOZ1kPsn+ActfleRUknuTfCDJU0ZfqiRJkjQ6ywbhJGuAQ8ANwDZgT5Jti7p9FJitqu8C3gO8ftSFSpIkSaM0zB7h7cB8VZ2pqoeBI8Cu/g5VdUdV/W03exe9W3pKkiRJE2uYILweONs3v9C1LeVm4HevpChJkiRppQ1zZ7kMaKuBHZOXArPADy2xfC+wF2DTpk1DlihJkiSN3jB7hBeAjX3zG4BzizsleQHwC8DOqvryoBVV1eGqmq2q2ZmZmcupV5IkSRqJYYLwCWBrki1J1gG7gaP9HZI8E3gTvRD84OjLlCRJkkZr2SBcVReAfcBx4D7g9qo6meRgkp1dt1uBxwHvTnJ3kqNLrE6SJEmaCMOcI0xVHQOOLWo70Df9ghHXJUmSJK0o7ywnSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZoySXYkOZ1kPsn+Act/MMmfJ7mQ5MZx1ChJk8AgLElTJMka4BBwA7AN2JNk26JunwRuAt6xutVJ0mRZO+4CJEkjtR2Yr6ozAEmOALuAUxc7VNUD3bKvjaNASZoU7hGWpOmyHjjbN7/QtUmSFjEIS9J0yYC2uqwVJXuTzCWZO3/+/BWWJUmTxyAsSdNlAdjYN78BOHc5K6qqw1U1W1WzMzMzIylOkiaJQViSpssJYGuSLUnWAbuBo2OuSZImkkFYkqZIVV0A9gHHgfuA26vqZJKDSXYCJPneJAvAS4A3JTk5voolaXy8aoQkTZmqOgYcW9R2oG/6BL1TJiSpae4RliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNckgLEmSpCYZhCVJktQkg7AkSZKaZBCWJElSkwzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJhmEJUmS1CSDsCRJkppkEJYkSVKTDMKSJElqkkFYkiRJTTIIS5IkqUkGYUmSJDXJICxJkqQmGYQlSZLUJIOwJEmSmmQQliRJUpMMwpIkSWqSQViSJElNMghLkiSpSQZhSZIkNWmoIJxkR5LTSeaT7B+w/FuSvKtb/uEkm0ddqCRpOI7ZkjScZYNwkjXAIeAGYBuwJ8m2Rd1uBh6qqm8H3gD851EXKklanmO2JA1vmD3C24H5qjpTVQ8DR4Bdi/rsAt7aTb8HeH6SjK5MSdKQHLMlaUjDBOH1wNm++YWubWCfqroAfA741lEUKEl6VByzJWlIa4foM2gvQV1GH5LsBfZ2s19IcnqI17+aXAt8atxFLCVtHfx0W0yOadwWTxlxGaPkmP3oTOzn03FicrgtJscVbIuB4/YwQXgB2Ng3vwE4t0SfhSRrgScAn1m8oqo6DBweptqrUZK5qpoddx1yW0wSt8Wqc8x+FPx8Tga3w+RobVsMc2rECWBrki1J1gG7gaOL+hwFXtZN3wj8YVU9Yu+CJGnFOWZL0pCW3SNcVReS7AOOA2uAt1TVySQHgbmqOgr8BvD2JPP09irsXsmiJUmDOWZL0vDiToDRSbK3O5SoMXNbTA63hSaZn8/J4HaYHK1tC4OwJEmSmuQtliVJktSkqzoIJ/lqkruTfDzJ7yR54ojWuznJx0exrkXrvSXJX3c1353kdaN+jb7Xuj7Ji1Zq/Suhb3vek+TPk3z/CrzGbJI3jnq90yDJP09SSZ6+xPLbkty4zDpuS3J/tx0/keQ/jrjGHx1wlzRdJRyzL/lajtmDX8Mx+xIct6/cVR2EgS9W1fVV9Qx6X/j4qXEXNIQ3dDVfX1X7h31Sd9vUR+N64KoaVPnG9vxu4LXAfxr1C1TVXFW9ctTrnRJ7gA9x5V+cek1VXU/vM/iyJFuuuLJv+FF6tw3W1ckxe2mO2QM4Zi/LcfsKXe1BuN+ddHdPSvK4JB/o/kL9WJJdXfvmJPcleXOSk0l+L8lju2XP6v6qvZO+wTnJY5L8ZreejyZ5Xtd+U5L3dns17k+yL8mruj53JXnSsIUneX73vI8leUuSb+naH0hyIMmHgJckeWqS/53kI0n+5OJfgEle0u1huSfJH3eXTDoI/ET3F95PjOQdXl2PBx6Cpbdnt+w/dH/B/n6Sdyb5+a79e5Pcm+TOJLde3FuU5LlJ3tdN39K93x9McibJK5db77RK8jjgOcDNdANqen4lyakk7we+ra//gSQnus/d4WTg7Xkf0/37/7rnLPU5X6r9dd1r35vkv3R7m3YCt3af66eu1PuhVeGY7ZjtmH0FHLdHpKqu2gfwhe7fNcC7gR3d/Frg8d30tcA8vTspbQYuANd3y24HXtpN3wv8UDd9K/DxbvrVwG92008HPknvg3JTt95rgBl6tyh9RdfvDcDPDqj3FuCvgbu7xz/r1nUWuK7r87aLzwUeAP5d3/M/AGztpr+P3rU/AT4GrO+mn9j9exPwK+PeRo9ye361e18+0b2fz1pme852/R/bbYe/BH6+6/dx4Pu76df1bc/nAu/r2x5/BnxLt95PA998qfVO6wN4KfAb3fSfAd8D/Bjw+93P1z8GPgvc2PV5Ut9z3w78SDd9G3B/9/59Afjlrn3g5/wS7U8CTvONL/Q+sW/9N477/fJx2Z8zx+xyzMYxe1Tvv+P2CB5X+x7hxya5m94Pw5PobXzo/cD9cpJ7gT+gt9fhH3bL7q+qu7vpjwCbkzyB3gb7o6797X2v8QMX56vqE8BfAdd1y+6oqs9X1Xl6g8DvdO0fozeAD9J/mO048LSupr/olr8V+MG+/u+Cr//l9/3Au7v/85uAJ3d9/hS4LcnL6X34r1YXD7M9HdgBvK37i3Wp7fkDwG9X1Rer6vN073965x1eU1V/1q33HZd4zfdX1Zer6lPAg5da75TbAxzppo908z8IvLOqvlpV54A/7Ov/vCQfTvIx4IeB7+xbdvEQ2z8Cnt/tEVjqc75U+98AXwJ+PcmPAX872v+uxsQxu8cx2zF7FBy3R2CYWyxPsi9W1fXdoPg+eofH3gj8JL2/+J9VVV9J8gDf2N3/5b7nf5XeX5ABlrqO3KBDBxf1r+trffNfY/j39lLrh+7wBL3TWD7bfVD/jqp6RZLvA14M3J3kEX2uNlV1Z5Jr6W3HFzF4ey713i33nvZb/HlY+yiff9VL8q30BsVnJCl6v5gL+F8M+LlI8hjgV4HZqjqb5Ba+8fP1dVX1hSQfpPdL6veWevlBjdW7KcR24Pn0Dvnt62rU1c0xG8fsARyzHyXH7dG52vcIA1BVnwNeCfx8km8GngA82P0APg94yjLP/yzwuSQ/0DX9ZN/iP744n+Q6YBO9Xf+j8gl6ezi+vZv/l8AfLe5UVX8D3J/kJV0tSfLd3fRTq+rDVXUA+BSwEfg8vUNEV6X0zqVbQ2/P0VLb80PAj6R3TuDj6P1SoaoeAj6f5Nldv0f7JYKB651iNwJvq6qnVNXmqtpI7zDZZ4DdSdYkeTLwvK7/xcHzU937M/AbyUnW0jsc/H9Y+nM+sL1b7xOq6hi9Q24Xg8JV/blWj2O2Y7Zj9hVz3B6RqQjCAFX1UeAeej9A/wOYTTJHb0D8xBCr+NfAofS+ePHFvvZfBdZ0hxLeBdxUVV8etILLrPtL3Wu/u3uNrwH/fYnuPwncnOQe4CRw8QsIt3YnrH+c3i+Be4A7gG25ur548diu3rvpvdcvq6qvssT2rKoTwFF6/9/fAuboHe6E3pcHDnfbM33ty1pmvdNoD729CP3+J71DZH9J77Dxr9H9su9CyJu79vcCJxY999ZuG97b9fmtpT7nl/j8XwO8rzu0+kfAz3XrPgK8Jr0vaUzely40NMdsx2wcs6+E4/aIeGc5XdWSPK47lPP36P1C2VtVf36xveuzH3hyVf3Mla53Rf4TktQIx2xNmqv9HGHpcHoX6n4M8Na+ge/FSV5L7zP+V/S+kT2K9UqSLp9jtiaKe4QlSZLUpKk5R1iSJEl6NAzCkiRJapJBWJIkSU0yCEuSJKlJBmFJkiQ1ySAsSZKkJv1/emhunzA2+cUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# These numbers need to be checked my niggi\n",
    "numBaseClassifiers = 500\n",
    "maxdepth = 10\n",
    "\n",
    "# Accuracy scores\n",
    "trainAcc = []\n",
    "testAcc = []\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=numBaseClassifiers)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_predTrain = rf.predict(X_train)\n",
    "rf_y_predTest = rf.predict(X_test)\n",
    "trainAcc.append(metrics.accuracy_score(y_train, rf_y_predTrain))\n",
    "testAcc.append(metrics.accuracy_score(y_test, rf_y_predTest))\n",
    "\n",
    "\n",
    "# Bagging\n",
    "bg = ensemble.BaggingClassifier(DecisionTreeClassifier(max_depth=maxdepth),n_estimators=numBaseClassifiers)\n",
    "bg.fit(X_train, y_train)\n",
    "bg_y_predTrain = bg.predict(X_train)\n",
    "bg_y_predTest = bg.predict(X_test)\n",
    "trainAcc.append(metrics.accuracy_score(y_train, bg_y_predTrain))\n",
    "testAcc.append(metrics.accuracy_score(y_test, bg_y_predTest))\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "ab = ensemble.AdaBoostClassifier(DecisionTreeClassifier(max_depth=maxdepth),n_estimators=numBaseClassifiers)\n",
    "ab.fit(X_train, y_train)\n",
    "ab_y_predTrain = clf.predict(X_train)\n",
    "ab_y_predTest = clf.predict(X_test)\n",
    "trainAcc.append(metrics.accuracy_score(y_train, ab_y_predTrain))\n",
    "testAcc.append(metrics.accuracy_score(y_test, ab_y_predTest))\n",
    "    \n",
    "    \n",
    "\n",
    "print(trainAcc)\n",
    "print(testAcc)\n",
    "\n",
    "methods = ['Random Forest', 'Bagging', 'AdaBoost']\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "ax1.bar([1.5,2.5,3.5], trainAcc)\n",
    "ax1.set_xticks([1.5,2.5,3.5])\n",
    "ax1.set_xticklabels(methods)\n",
    "ax2.bar([1.5,2.5,3.5], testAcc)\n",
    "ax2.set_xticks([1.5,2.5,3.5])\n",
    "ax2.set_xticklabels(methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]\n",
    "LRtrainAcc = []\n",
    "LRtestAcc = []\n",
    "SVMtrainAcc = []\n",
    "SVMtestAcc = []\n",
    "\n",
    "for param in C:\n",
    "    print(param)\n",
    "    clf = linear_model.LogisticRegression(C=param)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predTrain = clf.predict(X_train)\n",
    "    y_predTest = clf.predict(X_test)\n",
    "    LRtrainAcc.append(metrics.accuracy_score(y_train, y_predTrain))\n",
    "    LRtestAcc.append(metrics.accuracy_score(y_test, y_predTest))\n",
    "\n",
    "    clf = SVC(C=param,kernel='linear')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predTrain = clf.predict(X_train)\n",
    "    y_predTest = clf.predict(X_test)\n",
    "    SVMtrainAcc.append(metrics.accuracy_score(y_train, y_predTrain))\n",
    "    SVMtestAcc.append(metrics.accuracy_score(y_test, y_predTest))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "ax1.plot(C, LRtrainAcc, 'ro-', C, LRtestAcc,'bv--')\n",
    "ax1.legend(['Training Accuracy','Test Accuracy'])\n",
    "ax1.set_xlabel('C')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "\n",
    "ax2.plot(C, SVMtrainAcc, 'ro-', C, SVMtestAcc,'bv--')\n",
    "ax2.legend(['Training Accuracy','Test Accuracy'])\n",
    "ax2.set_xlabel('C')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_ylabel('Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Out of the models tuned with the above algorithms,\n",
    "select the best model and clearly justify your choice,\n",
    "and evaluate its performance on the test set. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This library will work for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#metrics.accuracy_score() is the function needed. y_test and y_pred are the arguments we'll use\n",
    "\n",
    "\n",
    "def get_best(prediction_values):\n",
    "    # for loop\n",
    "    best_value = -1\n",
    "    return best_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_random_forest_implementation():\n",
    "    # random forest\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import metrics\n",
    "    # rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    # rf.fit(X, y) # x is features and y is the label\n",
    "    # # to get the predictions we use\n",
    "    # prediction = rf.predict(arg) # where arg1 is the test features\n",
    "    # # Calculate mean absolute percentage error (MAPE)\n",
    "    # mape = 100 * (errors / test_labels)# Calculate and display accuracy\n",
    "    # accuracy = 100 - np.mean(mape)\n",
    "    # print('Accuracy:', round(accuracy, 2), '%.')\n",
    "    # ### prediction_values['random_forest'] = random_forest_prediction\n",
    "    rf = RandomForestClassifier(random_state=0, max_features=10)\n",
    "    rfModel = rf.fit(X_train, y_train)\n",
    "    y_pred = rfModel.predict(X_test)\n",
    "    print('Accuracy on test data is %.2f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    # print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    # print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    # print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
