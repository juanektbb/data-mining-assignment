{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cell below imports the relevant libraries and read the data from the specified files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('creditdefault_train.csv', header='infer')\n",
    "test_data = pd.read_csv('creditdefault_test.csv', header='infer')\n",
    "\n",
    "\n",
    "\n",
    "# X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "# X2: Gender (1 = male; 2 = female).\n",
    "# X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "# X4: Marital status (1 = married; 2 = single; 3 = others).\n",
    "# X5: Age (year).\n",
    "# X6 - X11: History of past payment. One tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "# X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "# X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
    "\n",
    "\n",
    "\n",
    "# Separate classes from dataset\n",
    "y_train = train_data['Y']\n",
    "X_train = train_data.drop(['Y'],axis=1)\n",
    "\n",
    "y_test = test_data['Y']\n",
    "X_test = test_data.drop(['Y'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.6929333333333333, 2: 0.7646, 3: 0.7351333333333333, 4: 0.7670666666666667, 5: 0.7523333333333333}\n"
     ]
    }
   ],
   "source": [
    "# KNN for 1 to 10\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = {}\n",
    "total_k = 6\n",
    "\n",
    "for k in range(1, total_k):\n",
    "    \n",
    "    # Initialize KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict classes for testing data\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Store the total accuracy values and percentage\n",
    "    scores[k] = metrics.accuracy_score(y_test, y_pred, normalize = False) / len(y_test)\n",
    "    \n",
    "\n",
    "print(scores)  \n",
    "\n",
    "\n",
    "# Juan: I need to build a function to find the best of scores\n",
    "# Use this: print('Accuracy on test data is %.2f' % (accuracy_score(testY, predY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7999333333333334\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=12)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred, normalize = False) / len(y_test)\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing Python and any relevant libraries,\\nyou are required to build the best predictive model\\nby tuning models using cross validation on the training dataset\\nwith each of the following algorithms (seen in class):\\nkNN, decision trees, Random Forest, Bagging, Boosting, and SVM.\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Using Python and any relevant libraries,\n",
    "you are required to build the best predictive model\n",
    "by tuning models using cross validation on the training dataset\n",
    "with each of the following algorithms (seen in class):\n",
    "kNN, decision trees, Random Forest, Bagging, Boosting, and SVM.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing other Machine Learning libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-46ff6f3ab961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x is features and y is the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# to get the predictions we use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# where arg1 is the test features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_values = {}\n",
    "\n",
    "\n",
    "\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(X, y) # x is features and y is the label\n",
    "# to get the predictions we use\n",
    "prediction = rf.predict(arg) # where arg1 is the test features\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "### prediction_values['random_forest'] = random_forest_prediction\n",
    "\n",
    "\n",
    "# bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "### prediction_values['bagging'] = bagging_prediction\n",
    "\n",
    "\n",
    "# boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "classifier = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200\n",
    ")\n",
    "classifier.fit(train_X, train_y)\n",
    "predictions = classifier.predict(test_X)\n",
    "confusion_matrix(test_y, predictions)\n",
    "### prediction_values['boosting'] = boosting_prediction\n",
    "\n",
    "\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "### prediction_values['svm'] = svm_prediction\n",
    "\n",
    "\n",
    "best_value = get_best(prediction_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Out of the models tuned with the above algorithms,\n",
    "select the best model and clearly justify your choice,\n",
    "and evaluate its performance on the test set. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This library will work for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#metrics.accuracy_score() is the function needed. y_test and y_pred are the arguments we'll use\n",
    "\n",
    "\n",
    "def get_best(prediction_values):\n",
    "    # for loop\n",
    "    best_value = -1\n",
    "    return best_value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
