{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_B2I27R-CVC5"
   },
   "source": [
    "# Part 2: Real credit risk data\n",
    "### By: Gokhan Arkan & Juan Diaz\n",
    "\n",
    "The cell below imports the required libraries and both testing and training data needed for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "ypB7YYhSQ02_",
    "outputId": "d57ce10d-caa7-4f3c-88e4-b615e9cfdcc5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, precision_recall_curve\n",
    "\n",
    "train_data = pd.read_csv('creditdefault_train.csv', header='infer')\n",
    "test_data = pd.read_csv('creditdefault_test.csv', header='infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation of dummy data\n",
    "\n",
    "Some features of the training and testing sets are treated as numerical features, but they are categorical. For example, the education field (X3) has range 1 - 4, but each value can be a separate binary feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqZwEnH0CVDG"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  DATA PREPARATION MAIN FUNCTION\n",
    "  This function works for both Training and Testing data as they both have the same features\n",
    "  It requires the set to be prepare and returns the final set\n",
    "'''\n",
    "def data_preparation(dataset):\n",
    "\n",
    "  # X3: Education field is divided in 3 binary features, last one is implicit when all three features are equal to 0\n",
    "  dataset['graduated'] = (dataset['X3'] == 1).astype('int')\n",
    "  dataset['university'] = (dataset['X3'] == 2).astype('int')\n",
    "  dataset['high_school'] = (dataset['X3'] == 3).astype('int')\n",
    "  dataset.drop('X3', axis=1, inplace=True)\n",
    "\n",
    "  # X2: Gender field is binary as well. Male = 1 and Female = 0\n",
    "  dataset['male'] = (dataset['X2'] == 1).astype('int')\n",
    "  dataset.drop('X2', axis=1, inplace=True)\n",
    "\n",
    "  # X4: Married field is also binary. Married = 1 and Single = 0\n",
    "  dataset['married'] = (dataset['X4'] == 1).astype('int')\n",
    "  dataset.drop('X4', axis=1, inplace=True)\n",
    "\n",
    "  # X6 - X11: History of past payments. All values less than 0 are converted to 0 meaning they are not delayed on payments\n",
    "  are_paid = ['X6', 'X7', 'X8', 'X9', 'X10', 'X11']\n",
    "  for column in are_paid:\n",
    "    dataset.loc[dataset[column] <= 0, column] = 0\n",
    "\n",
    "  # Return the modified dataset\n",
    "  return dataset\n",
    "\n",
    "\n",
    "# Call for preparation of the data using the main function\n",
    "train_data = data_preparation(train_data)\n",
    "test_data = data_preparation(test_data)\n",
    "\n",
    "\n",
    "# Separate classes from dataset for training and testing\n",
    "y_train = train_data['Y']\n",
    "X_train = train_data.drop(['Y'],axis=1)\n",
    "\n",
    "y_test = test_data['Y']\n",
    "X_test = test_data.drop(['Y'],axis=1)\n",
    "\n",
    "\n",
    "'''\n",
    "  Use RobustScaler preprocessor to convert the data to the same scale \n",
    "  as certain features like `age` have a larger scale.\n",
    "'''\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "X_train = RobustScaler().fit_transform(X_train)\n",
    "X_test = RobustScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation\n",
    "\n",
    "It evaluates all six algorithms using cross validation and plot them in a table to analize their accuracy and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRwF3K91wwuq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Bagging Accuracy</th>\n",
       "      <th>Ada Boost</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.791733</td>\n",
       "      <td>0.728200</td>\n",
       "      <td>0.807333</td>\n",
       "      <td>0.818467</td>\n",
       "      <td>0.815933</td>\n",
       "      <td>0.816133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Deviation</th>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.017430</td>\n",
       "      <td>0.017495</td>\n",
       "      <td>0.018825</td>\n",
       "      <td>0.013918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         KNN  Decision Tree  Bagging Accuracy  Ada Boost  \\\n",
       "Accuracy            0.791733       0.728200          0.807333   0.818467   \n",
       "Standard Deviation  0.013289       0.016114          0.017430   0.017495   \n",
       "\n",
       "                    Random Forest       SVC  \n",
       "Accuracy                 0.815933  0.816133  \n",
       "Standard Deviation       0.018825  0.013918  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Prepare the data frame for visualizing the cross validation\n",
    "crossvalidator = pd.DataFrame(index=['Accuracy', 'Standard Deviation'], columns=[])\n",
    "\n",
    "# Function to populate the evaluation of each model\n",
    "def eval_crossval(model_name, crossval):\n",
    "  crossvalidator.loc['Accuracy', model_name] = crossval['test_score'].mean()\n",
    "  crossvalidator.loc['Standard Deviation', model_name] = crossval['test_score'].std() * 2\n",
    "\n",
    "\n",
    "# Compute cross validation for KNN\n",
    "knn = KNeighborsClassifier()\n",
    "crossknn = cross_validate(knn, X_train, y_train, cv=5)\n",
    "eval_crossval(\"KNN\", crossknn)\n",
    "\n",
    "# Compute cross validation for Decision Tree\n",
    "dtc = DecisionTreeClassifier()\n",
    "crossdtc = cross_validate(dtc, X_train, y_train, cv=5)\n",
    "eval_crossval(\"Decision Tree\", crossdtc)\n",
    "\n",
    "# Compute cross validation for Bagging Accuracy\n",
    "bag = BaggingClassifier()\n",
    "crossbag = cross_validate(bag, X_train, y_train, cv=5)\n",
    "eval_crossval(\"Bagging Accuracy\", crossbag)\n",
    "\n",
    "# Compute cross validation for Ada Boost\n",
    "abc = AdaBoostClassifier()\n",
    "crossabc = cross_validate(abc, X_train, y_train, cv=5)\n",
    "eval_crossval(\"Ada Boost\", crossabc)\n",
    "\n",
    "# Compute cross validation for Random Forest\n",
    "rfc = RandomForestClassifier()\n",
    "crossrfc = cross_validate(rfc, X_train, y_train, cv=5)\n",
    "eval_crossval(\"Random Forest\", crossrfc)\n",
    "\n",
    "# Compute cross validation for SVC\n",
    "svc = SVC()\n",
    "crosssvc = cross_validate(svc, X_train, y_train, cv=5)\n",
    "eval_crossval(\"SVC\", crosssvc)\n",
    "\n",
    "\n",
    "# Display table of cross validation\n",
    "crossvalidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation analysis\n",
    "\n",
    "According to the cross-validation table above, the algorithm with higher performance is Ada Boost. However, all the other algorithms are very close to it, except the Decision Tree. Since AdaBoost and Bagging use an implementation of Decision Trees in the first place, it gives a better precision for the data. In the end, these two ensemble algorithms worked better than the other ones. On the other hand, although SVC gave accurate prediction, since the nature of the algorithm, we expect more computation time compared to the other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for visualizing data\n",
    "They will be use several times for plotting graphs or displaying tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTbIhQnYREtd"
   },
   "outputs": [],
   "source": [
    "# Prepare the data frame for visualizing the final models evaluations\n",
    "evaluator = pd.DataFrame(index=['Accuracy', 'Precision', 'Recall'], columns=[])\n",
    "\n",
    "\n",
    "# Function to populate the evaluation of each model \n",
    "def eval_module(model_name, y_truth, y_pred):\n",
    "  evaluator.loc['Accuracy', model_name] = accuracy_score(y_truth, y_pred)\n",
    "  evaluator.loc['Precision', model_name] = precision_score(y_truth, y_pred)\n",
    "  evaluator.loc['Recall', model_name] = recall_score(y_truth, y_pred)\n",
    "\n",
    "\n",
    "# Function to visualize the evaluation of all models\n",
    "def visual_evaluation(evaluation):\n",
    "  fig, ax = plt.subplots(figsize=(8,5))\n",
    "  evaluation.plot(kind='barh', ax=ax)\n",
    "  ax.grid()\n",
    "\n",
    "\n",
    "# Function to print the confusion matrix of a given module\n",
    "def print_conf_matrix(cm):\n",
    "  labels = ['Payers', 'Defaulters']\n",
    "  conf = pd.DataFrame(data=cm, index=labels, columns=labels)\n",
    "  conf.index.name = \"TRUE\"\n",
    "  conf.columns.name = \"PREDICTION\"\n",
    "  conf.loc['Total'] = conf.sum()\n",
    "  conf['Total'] = conf.sum(axis=1)\n",
    "  return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for manipulating data\n",
    "The functions here are used for calculations in the code of certain models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a dictionary with indexes and accuracies and finds the highest and returns it. Use for KNN, Adaboost and Bagging\n",
    "def find_best_param(accuracy_dict):\n",
    "    largest, index = 0, 0\n",
    "\n",
    "    # Loop the dictionary\n",
    "    for i in accuracy_dict:\n",
    "\n",
    "        # This iteration is higher than previous ones\n",
    "        if largest < accuracy_dict[i]:\n",
    "            largest = accuracy_dict[i]\n",
    "            index = i\n",
    "            \n",
    "    # Return index and its best accuracy\n",
    "    return (index, largest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier algorithm\n",
    "This implementation finds the best K in a range of 1 to 9, store their performance and print the confusion matrix of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "zWHIW3vGCVDY",
    "outputId": "99fcb961-827c-477b-dc1d-d5f36aae44ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy at K = 9 of 0.806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PREDICTION</th>\n",
       "      <th>Payers</th>\n",
       "      <th>Defaulters</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRUE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Payers</th>\n",
       "      <td>10987</td>\n",
       "      <td>695</td>\n",
       "      <td>11682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defaulters</th>\n",
       "      <td>2213</td>\n",
       "      <td>1105</td>\n",
       "      <td>3318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>13200</td>\n",
       "      <td>1800</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PREDICTION  Payers  Defaulters  Total\n",
       "TRUE                                 \n",
       "Payers       10987         695  11682\n",
       "Defaulters    2213        1105   3318\n",
       "Total        13200        1800  15000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN for K = 1 to 9\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scores_knn = {}\n",
    "total_k = 9 # Calculate distances for K = 1 to 9\n",
    "\n",
    "# Train data K times\n",
    "for k in range(1, total_k + 1):\n",
    "\n",
    "    # Initialize KNN for k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict classes and store the accuracy \n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores_knn[k] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Find the best K using the helper function\n",
    "best_k = find_best_param(scores_knn)\n",
    "\n",
    "print('Best accuracy at K =', best_k[0], 'of %.3f' % best_k[1])  \n",
    "\n",
    "# Compute the final KNN with the best K achieved\n",
    "knn_best_k = KNeighborsClassifier(n_neighbors = best_k[0])\n",
    "knn_best_k.fit(X_train, y_train)\n",
    "\n",
    "# Best predictor found\n",
    "y_pred_best = knn_best_k.predict(X_test)\n",
    "\n",
    "# Evaluation of this module\n",
    "eval_module(\"KNN\", y_test, y_pred_best)\n",
    "\n",
    "# Print the confusion matrix of this model\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "print_conf_matrix(con_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier algorithm\n",
    "This implementation computes and print the confusion matrix of Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "recN3FILCVDf",
    "outputId": "2f456c45-4f24-4395-cf99-ce8b679bb600"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PREDICTION</th>\n",
       "      <th>Payers</th>\n",
       "      <th>Defaulters</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRUE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Payers</th>\n",
       "      <td>10604</td>\n",
       "      <td>1078</td>\n",
       "      <td>11682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defaulters</th>\n",
       "      <td>2255</td>\n",
       "      <td>1063</td>\n",
       "      <td>3318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>12859</td>\n",
       "      <td>2141</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PREDICTION  Payers  Defaulters  Total\n",
       "TRUE                                 \n",
       "Payers       10604        1078  11682\n",
       "Defaulters    2255        1063   3318\n",
       "Total        12859        2141  15000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# clf = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "clf = DecisionTreeClassifier(min_samples_split=30, min_samples_leaf=10, random_state=10)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluation of this module\n",
    "eval_module(\"DecisionTree\", y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix of this model\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "print_conf_matrix(con_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "This implementation uses the Random Forest algorithm fitting with 500 base classifiers, sends the prediction accuracy to the evaluation methods and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "0seU1IM27L4O",
    "outputId": "5fc3b0c4-325b-4aa0-ccb8-56bca22e366b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PREDICTION</th>\n",
       "      <th>Payers</th>\n",
       "      <th>Defaulters</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRUE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Payers</th>\n",
       "      <td>11086</td>\n",
       "      <td>596</td>\n",
       "      <td>11682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defaulters</th>\n",
       "      <td>2163</td>\n",
       "      <td>1155</td>\n",
       "      <td>3318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>13249</td>\n",
       "      <td>1751</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PREDICTION  Payers  Defaulters  Total\n",
       "TRUE                                 \n",
       "Payers       11086         596  11682\n",
       "Defaulters    2163        1155   3318\n",
       "Total        13249        1751  15000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 500 base classifiers fit to the 2-dimensional dataset\n",
    "numBaseClassifiers = 500\n",
    "\n",
    "# Initialize the Random Forest Classfier and fit the data to the model\n",
    "rf = RandomForestClassifier(n_estimators=numBaseClassifiers)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict classes and store the accuracy \n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluation of this model\n",
    "eval_module(\"Random Forest\", y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix of this model\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "print_conf_matrix(con_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier\n",
    "This implementation uses the Bagging algorithm along with Decision Trees, fitting with 500 base classifiers. It also iterates a list of max depth values and gets the best one. With the best picked depth, the model recalculates and sends the prediction data to evaluation. At the end it prints the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "on_434I2-ALG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth is at = 8 of 0.818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PREDICTION</th>\n",
       "      <th>Payers</th>\n",
       "      <th>Defaulters</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRUE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Payers</th>\n",
       "      <td>11119</td>\n",
       "      <td>563</td>\n",
       "      <td>11682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defaulters</th>\n",
       "      <td>2172</td>\n",
       "      <td>1146</td>\n",
       "      <td>3318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>13291</td>\n",
       "      <td>1709</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PREDICTION  Payers  Defaulters  Total\n",
       "TRUE                                 \n",
       "Payers       11119         563  11682\n",
       "Defaulters    2172        1146   3318\n",
       "Total        13291        1709  15000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 500 base classifiers fit to the 2-dimensional dataset\n",
    "numBaseClassifiers = 500\n",
    "\n",
    "# Checking different sizes of max depth\n",
    "maxdepths = [2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,45,50]\n",
    "\n",
    "# Keeping the individual max depth scores in a dictionary to get best one\n",
    "scores_bagging = {}\n",
    "\n",
    "for depth in maxdepths:\n",
    "\n",
    "  # Initialize the Bagging Classifier and fit the data to the model\n",
    "  bg = BaggingClassifier(DecisionTreeClassifier(max_depth=depth),n_estimators=numBaseClassifiers)\n",
    "  bg.fit(X_train, y_train)\n",
    "\n",
    "  # Predict classes and store the accuracy\n",
    "  y_pred = bg.predict(X_test)\n",
    "\n",
    "  # Putting the accuracy score to the dictionary\n",
    "  scores_bagging[depth] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "best_depth = find_best_param(scores_bagging)\n",
    "bagging_best_depth = BaggingClassifier(DecisionTreeClassifier(max_depth=best_depth[0]),n_estimators=numBaseClassifiers)\n",
    "\n",
    "bagging_best_depth.fit(X_train, y_train)\n",
    "y_pred_best = bagging_best_depth.predict(X_test)\n",
    "\n",
    "# Evaluation of this model\n",
    "eval_module(\"Bagging\", y_test, y_pred_best)\n",
    "\n",
    "print('Best depth is at =', best_depth[0], 'of %.3f' % best_depth[1])\n",
    "\n",
    "# Print the confusion matrix of this model\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "print_conf_matrix(con_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier\n",
    "This implementation uses the AdaBoost algorithm along with Decision Trees, fitting with 500 base classifiers. It also iterates a list of max depth values and gets the best one. With the best picked depth, the model recalculates and sends the prediction data to evaluation. At the end it prints the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "colab_type": "code",
    "id": "vrzgsY7sCVDu",
    "outputId": "5bc57adf-d1e4-4483-b0b3-ed1900987813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth is at = 10 of 0.794\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PREDICTION</th>\n",
       "      <th>Payers</th>\n",
       "      <th>Defaulters</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRUE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Payers</th>\n",
       "      <td>10831</td>\n",
       "      <td>851</td>\n",
       "      <td>11682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defaulters</th>\n",
       "      <td>2235</td>\n",
       "      <td>1083</td>\n",
       "      <td>3318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>13066</td>\n",
       "      <td>1934</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PREDICTION  Payers  Defaulters  Total\n",
       "TRUE                                 \n",
       "Payers       10831         851  11682\n",
       "Defaulters    2235        1083   3318\n",
       "Total        13066        1934  15000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 500 base classifiers fit to the 2-dimensional dataset\n",
    "numBaseClassifiers = 500\n",
    "\n",
    "# Checking different sizes of max depth\n",
    "# maxdepths = [2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,45,50]\n",
    "maxdepths = [10]\n",
    "\n",
    "# Keeping the individual max depth scores in a dictionary to get best one\n",
    "scores_adaboost = {}\n",
    "\n",
    "for depth in maxdepths:\n",
    "  # Initialize the AdaBoost Classifier and fit the data to the model\n",
    "  ab = AdaBoostClassifier(DecisionTreeClassifier(max_depth=depth),n_estimators=numBaseClassifiers)\n",
    "  ab.fit(X_train, y_train)\n",
    "\n",
    "  # Predict classes and store the accuracy\n",
    "  y_pred = ab.predict(X_test)\n",
    "\n",
    "  # Putting the accuracy score to the dictionary\n",
    "  scores_adaboost[depth] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "best_depth = find_best_param(scores_adaboost)\n",
    "adaboost_best_depth = AdaBoostClassifier(DecisionTreeClassifier(max_depth=best_depth[0]),n_estimators=numBaseClassifiers)\n",
    "\n",
    "adaboost_best_depth.fit(X_train, y_train)\n",
    "y_pred_best = adaboost_best_depth.predict(X_test)\n",
    "\n",
    "eval_module(\"AdaBoost\", y_test, y_pred_best)\n",
    "print('Best depth is at =', best_depth[0], 'of %.3f' % best_depth[1])\n",
    "\n",
    "# Print the confusion matrix of this model\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "print_conf_matrix(con_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "This implementation uses Linear SVM approach with a list of C parameters. It iterates through every parameter and pick the best one. With the best parameter, the implementation calculates the prediction accuracy and sends the evaluation methods. At the end, it prints a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8APL9bbCVDz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param is at = 1 of 0.817\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PREDICTION</th>\n",
       "      <th>Payers</th>\n",
       "      <th>Defaulters</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRUE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Payers</th>\n",
       "      <td>11007</td>\n",
       "      <td>675</td>\n",
       "      <td>11682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defaulters</th>\n",
       "      <td>2064</td>\n",
       "      <td>1254</td>\n",
       "      <td>3318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>13071</td>\n",
       "      <td>1929</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PREDICTION  Payers  Defaulters  Total\n",
       "TRUE                                 \n",
       "Payers       11007         675  11682\n",
       "Defaulters    2064        1254   3318\n",
       "Total        13071        1929  15000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Hyerparameter that controls the inverse of model complexity\n",
    "C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]\n",
    "\n",
    "# Keeping the individual hypeparameter scores in a dictionary to get best one\n",
    "scores_svm = {}\n",
    "\n",
    "for param in C:\n",
    "\n",
    "  # Initialize the SVM Classifier and fit the data to the model\n",
    "  svclassifier = SVC(kernel='linear', C=param)\n",
    "  svclassifier.fit(X_train, y_train)\n",
    "\n",
    "  # Predict classes and store the accuracy\n",
    "  y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "  # Putting the accuracy score to the dictionary\n",
    "  scores_svm[param] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "best_param = find_best_param(scores_svm)\n",
    "svm_best_param = SVC(kernel='linear', C=best_param[0])\n",
    "\n",
    "svm_best_param.fit(X_train, y_train)\n",
    "y_pred_best = svm_best_param.predict(X_test)\n",
    "\n",
    "eval_module(\"SVM\", y_test, y_pred_best)\n",
    "print('Best param is at =', best_param[0], 'of %.3f' % best_param[1])\n",
    "\n",
    "# Print the confusion matrix of this model\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "print_conf_matrix(con_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>79.020000</td>\n",
       "      <td>81.740000</td>\n",
       "      <td>80.613333</td>\n",
       "      <td>77.780000</td>\n",
       "      <td>81.606667</td>\n",
       "      <td>81.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>54.516640</td>\n",
       "      <td>65.007776</td>\n",
       "      <td>61.388889</td>\n",
       "      <td>49.649696</td>\n",
       "      <td>65.962307</td>\n",
       "      <td>67.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>31.103074</td>\n",
       "      <td>37.793852</td>\n",
       "      <td>33.303195</td>\n",
       "      <td>32.037372</td>\n",
       "      <td>34.810127</td>\n",
       "      <td>34.538879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AdaBoost        SVM        KNN  DecisionTree  Random Forest  \\\n",
       "Accuracy   79.020000  81.740000  80.613333     77.780000      81.606667   \n",
       "Precision  54.516640  65.007776  61.388889     49.649696      65.962307   \n",
       "Recall     31.103074  37.793852  33.303195     32.037372      34.810127   \n",
       "\n",
       "             Bagging  \n",
       "Accuracy   81.826667  \n",
       "Precision  67.411765  \n",
       "Recall     34.538879  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual_evaluation(evaluator*100)\n",
    "\n",
    "100*evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final evaluation\n",
    "This graph illustrates the performance of all the algorithms using the test data. The primary three keys to evaluate are:\n",
    "- Accuracy: How the model predicted correct and incorrect defaulters\n",
    "- Precision: How often the model predicted someone is a defaulter correctly\n",
    "- Recall: Proportion of actual defaulters that the model predicted\n",
    "\n",
    "In order to choose the metrics, we need to consider which mistakes to avoid. \n",
    "In this project, the most appropriate metric to look at is Recall to catch the False Negative who are the defaulters that were predicted as payers\n",
    "\n",
    "SVM performance is generally one of the best choices but especially its Recall the most beneficial for the data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}